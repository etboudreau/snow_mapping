{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The notebook is used to download planetscope images edited from notebook with custom requiremnets (Kehan Yang, kyang33@uw.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages and set up directories\n",
    "Planet has updated its API in March 2023, so some of the functions may not be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from get_planet import *\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authorize Planet account.\n",
    "You can copy and paste your planet API from your Planet Account setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup OK: API key valid\n"
     ]
    }
   ],
   "source": [
    "# If you're following along with this notebook, you can enter your API Key on the following line, and uncomment it:\n",
    "# os.environ['PLANET_API_KEY']='PLAKf9b6328484534380bcc8c6fa56cd27aa'\n",
    "# Setup the API Key from the `PL_API_KEY` environment variable\n",
    "PLANET_API_KEY = os.getenv('PLANET_API_KEY')\n",
    "\n",
    "#### Get your API Key and run validity check\n",
    "# This gets your API key and prompts you incase your API key is missing or if there are authentication issues\n",
    "\n",
    "## Get your API Key\n",
    "try:\n",
    "    PLANET_API_KEY = 'PLAK198d7255136b4c28b3cac7446a904121' #remove find_api_key and place your api key like 'api-key'\n",
    "except Exception as e:\n",
    "    print(\"Failed to get Planet Key: Try planet init or install Planet Command line tool\")\n",
    "    sys.exit()\n",
    "\n",
    "# check if API key is valid \n",
    "response = requests.get('https://api.planet.com/compute/ops/orders/v2',auth=(PLANET_API_KEY, \"\"))\n",
    "if response.status_code==200:\n",
    "    print('Setup OK: API key valid')\n",
    "else:\n",
    "    print(f'Failed with response code {response.status_code}: reinitialize using planet init')\n",
    "\n",
    "\n",
    "# Run 'planet init' in terminal; Type in planet account (email address) and password and run this chuck again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory for the geomtry, the format has to be geojson\n",
    "# dir_geom = './data/geom/'\n",
    "dir_geom = '/home/etboud/projects/data/geom/'\n",
    "\n",
    "# dir_root = './data/download/'\n",
    "dir_root = '/home/etboud/projects/data/download/'\n",
    "\n",
    "# directory where the images will be downloaded. \n",
    "dir_download = dir_root + 'images/'\n",
    "os.makedirs(dir_download, exist_ok=True)\n",
    "\n",
    "# directory for the download links and image ids \n",
    "dir_order_url =  dir_root + 'links/'\n",
    "os.makedirs(dir_order_url, exist_ok=True)\n",
    "\n",
    "# change the flag if search and/or download data are required.\n",
    "flag_search = True\n",
    "flag_order = True # if this is set to True, the data will be ordered and count in your plan\n",
    "flag_download = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start to search and/or download data\n",
    "If flag_download is set to False, the order will not be placed, and your quote will not be consumed. The total areas will be saved in a CSV file, allowing you to estimate the total size of the areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "/home/etboud/projects/data/download/links/2016_all_URLs.txt\n",
      "                                          file        index   ID\n",
      "0  /home/etboud/projects/data/geom/Q05.geojson  Q05.geojson  Q05\n",
      "Pandas(Index=0, file='/home/etboud/projects/data/geom/Q05.geojson', index='Q05.geojson', ID='Q05')\n",
      "Q05_2016\n",
      "Searching available images ------- \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/etboud/projects/snow_mapping2/download_planet_images.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bc-nicoleta-1.ce.washington.edu/home/etboud/projects/snow_mapping2/download_planet_images.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mif\u001b[39;00m ID_geom \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m order_urls\u001b[39m.\u001b[39mID_geom\u001b[39m.\u001b[39mto_list():\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bc-nicoleta-1.ce.washington.edu/home/etboud/projects/snow_mapping2/download_planet_images.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSearching available images ------- \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bc-nicoleta-1.ce.washington.edu/home/etboud/projects/snow_mapping2/download_planet_images.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     idlist \u001b[39m=\u001b[39m ft_iterate(item_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPSScene\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m# planet has changed the product item type from 'PSScene4Band' with PSScene\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bc-nicoleta-1.ce.washington.edu/home/etboud/projects/snow_mapping2/download_planet_images.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m             asset_type\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mortho_analytic_4b_sr\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bc-nicoleta-1.ce.washington.edu/home/etboud/projects/snow_mapping2/download_planet_images.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m             geom \u001b[39m=\u001b[39m read_geom(irow\u001b[39m.\u001b[39mfile),\u001b[39m#\".json\"),\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bc-nicoleta-1.ce.washington.edu/home/etboud/projects/snow_mapping2/download_planet_images.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m             start \u001b[39m=\u001b[39m start_time,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bc-nicoleta-1.ce.washington.edu/home/etboud/projects/snow_mapping2/download_planet_images.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m             end \u001b[39m=\u001b[39m end_time,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bc-nicoleta-1.ce.washington.edu/home/etboud/projects/snow_mapping2/download_planet_images.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m             cloud_cover \u001b[39m=\u001b[39m cloud_pct, \u001b[39m#cloud cover range 0-1 represting 0-100% so 0.5 means max allowed 50% cloud cover\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bc-nicoleta-1.ce.washington.edu/home/etboud/projects/snow_mapping2/download_planet_images.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m             ovp \u001b[39m=\u001b[39m overlap) \u001b[39m#% minimum % overlap 0-100\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bc-nicoleta-1.ce.washington.edu/home/etboud/projects/snow_mapping2/download_planet_images.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m     idlist[\u001b[39m'\u001b[39m\u001b[39mID_geom\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m ID_geom\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bc-nicoleta-1.ce.washington.edu/home/etboud/projects/snow_mapping2/download_planet_images.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m     \u001b[39mprint\u001b[39m(idlist\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/projects/snow_mapping2/get_planet.py:145\u001b[0m, in \u001b[0;36mft_iterate\u001b[0;34m(item_type, asset_type, geom, start, end, cloud_cover, ovp)\u001b[0m\n\u001b[1;32m    143\u001b[0m     ovp\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m \u001b[39m# 10% overlap at least\u001b[39;00m\n\u001b[1;32m    144\u001b[0m search_json \u001b[39m=\u001b[39m search_payload(item_type,asset_type,geom,start,end,cloud_cover)\n\u001b[0;32m--> 145\u001b[0m all_features \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m    146\u001b[0m     yield_features(\u001b[39m'\u001b[39m\u001b[39mhttps://api.planet.com/data/v1/quick-search\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    147\u001b[0m                    HTTPBasicAuth(PLANET_API_KEY, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m), search_json))\n\u001b[1;32m    148\u001b[0m image_ids \u001b[39m=\u001b[39m [x[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m all_features]\n\u001b[1;32m    149\u001b[0m aoi_shape \u001b[39m=\u001b[39m shape(geom)\n",
      "File \u001b[0;32m~/projects/snow_mapping2/get_planet.py:124\u001b[0m, in \u001b[0;36myield_features\u001b[0;34m(url, auth, payload)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39myield_features\u001b[39m(url,auth,payload):\n\u001b[1;32m    123\u001b[0m     page \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mpost(url, auth\u001b[39m=\u001b[39mauth, data\u001b[39m=\u001b[39mjson\u001b[39m.\u001b[39mdumps(payload),headers\u001b[39m=\u001b[39mheaders)\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m page\u001b[39m.\u001b[39mjson()[\u001b[39m'\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    125\u001b[0m         \u001b[39myield\u001b[39;00m feature\n\u001b[1;32m    126\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'features'"
     ]
    }
   ],
   "source": [
    "# define the searching period; \n",
    "years = [2016]\n",
    "# start and end date of each year\n",
    "start_date = '-06-01T00:00:00'\n",
    "end_date = '-06-30T12:00:00'\n",
    "\n",
    "for yr in years:\n",
    "    yr = str(yr)\n",
    "    print(yr)\n",
    "\n",
    "    if flag_search:\n",
    "        df_search = pd.DataFrame() # save all image ids\n",
    "        \n",
    "        #file to store url -- planet data download links\n",
    "        file_orders = dir_order_url + yr + '_all_URLs.txt'\n",
    "        start_time = yr + start_date\n",
    "        end_time = yr + end_date\n",
    "        print(file_orders)\n",
    "        \n",
    "        overlap = 99 # at least with 99% overlap \n",
    "        cloud_pct = 0.05 # no more than 5% cloud cover\n",
    "\n",
    "\n",
    "        #search for geojson file\n",
    "        fn = glob.glob(dir_geom + \"*geojson\")\n",
    "        ID_shp = [id.split(\"/\")[-1] for id in fn]\n",
    "        df = pd.DataFrame(data = {\n",
    "            \"file\": fn, \n",
    "            \"index\":  [i.split(\"/\")[-1] for i in fn],\n",
    "            \"ID\": [id.split(\"/\")[-1].split('.')[0] for id in fn]\n",
    "            })\n",
    "        df = df.sort_values(\"index\", ascending = True)\n",
    "\n",
    "        print(df.head())\n",
    "\n",
    "    # check whether the order url txt file is exist. if exist, read data; otherwise, creat file.\n",
    "        idx = 0 \n",
    "        if exists(file_orders):\n",
    "            order_urls = pd.read_csv(file_orders)\n",
    "        else:\n",
    "            order_urls = pd.DataFrame(columns = [\"index\",\"ID_geom\", \"order_url\"])\n",
    "            \n",
    "\n",
    "\n",
    "        for irow in df.itertuples():\n",
    "\n",
    "        # Search id \n",
    "            print(irow)\n",
    "            ID_geom = irow.ID.split(\".\")[0]+ '_' + yr\n",
    "            print(ID_geom)\n",
    "\n",
    "            if ID_geom not in order_urls.ID_geom.to_list():\n",
    "\n",
    "                print('Searching available images ------- ')\n",
    "                idlist = ft_iterate(item_type='PSScene', # planet has changed the product item type from 'PSScene4Band' with PSScene\n",
    "                        asset_type= 'ortho_analytic_4b_sr',\n",
    "                        geom = read_geom(irow.file),#\".json\"),\n",
    "                        start = start_time,\n",
    "                        end = end_time,\n",
    "                        cloud_cover = cloud_pct, #cloud cover range 0-1 represting 0-100% so 0.5 means max allowed 50% cloud cover\n",
    "                        ovp = overlap) #% minimum % overlap 0-100\n",
    "\n",
    "                idlist['ID_geom'] = ID_geom\n",
    "                print(idlist.shape)\n",
    "                idlist.sort_values(\"date\")\n",
    "                df_search = pd.concat([df_search, idlist])\n",
    "\n",
    "\n",
    "                # print(irow.file)\n",
    "                if(flag_order):\n",
    "                    payload_info = order_payload(Name_download = ID_geom, ID_imgs = idlist.id.values.tolist(), File_geom = irow.file)\n",
    "                    # print(payload_info)\n",
    "                    print(\"Pay order:\".format(),ID_geom)\n",
    "\n",
    "\n",
    "                    order_url = order_now(payload_info) # error response 400  \n",
    "\n",
    "                    order_urls.loc[idx, \"index\"] = idx        \n",
    "                    order_urls.loc[idx, \"ID_geom\"] = ID_geom\n",
    "                    order_urls.loc[idx, \"order_url\"] = order_url\n",
    "                    print(order_url)\n",
    "                    order_urls.loc[idx, \"NUM\"] = idlist.shape[0]  \n",
    "                    order_urls.loc[idx, \"Total area\"] = sum(idlist['estimated area'])  \n",
    "\n",
    "\n",
    "                    # order_urls.append(order_url)  # save all URLs\n",
    "                    order_urls.to_csv(file_orders, index = None)# save all URLs\n",
    "\n",
    "\n",
    "            idx = idx + 1\n",
    "        # save all satellite image id and geom info to one file\n",
    "        df_search.to_csv(dir_order_url+'all_image_info.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read order URL from file_orders\n",
    "flag_download = True\n",
    "fn = glob.glob(dir_order_url + '/*_all_URLs.txt')\n",
    "\n",
    "if flag_download:\n",
    "    for file_orders in fn:\n",
    "        order_urls_read = pd.read_csv(file_orders)\n",
    "\n",
    "        for url in order_urls_read.itertuples():\n",
    "            print(url.order_url)\n",
    "            # if poll_for_success(url.order_url):\n",
    "            if os.path.exists(dir_download + url.ID_geom):\n",
    "                print(\"Data have been downloaded\".format(), dir_download + url.ID_geom)\n",
    "            else:\n",
    "                print(\"start downloading data to\".format(), dir_download + url.ID_geom)\n",
    "                download_results(url.order_url,folder = dir_download + url.ID_geom)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
